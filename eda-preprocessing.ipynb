{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7379779,"sourceType":"datasetVersion","datasetId":4288635}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Importing Python libraries & \"AI vs. human text\" dataset**","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)'\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-16T05:41:22.132946Z","iopub.execute_input":"2024-03-16T05:41:22.133371Z","iopub.status.idle":"2024-03-16T05:41:22.142787Z","shell.execute_reply.started":"2024-03-16T05:41:22.133340Z","shell.execute_reply":"2024-03-16T05:41:22.141729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import PlaintextCorpusReader\n\ndf = pd.read_csv(\"/kaggle/input/ai-vs-human-text/AI_Human.csv\")\nprint(df.head())","metadata":{"execution":{"iopub.status.busy":"2024-03-16T06:19:49.908538Z","iopub.execute_input":"2024-03-16T06:19:49.908983Z","iopub.status.idle":"2024-03-16T06:20:08.175007Z","shell.execute_reply.started":"2024-03-16T06:19:49.908952Z","shell.execute_reply":"2024-03-16T06:20:08.173759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['length']=df['text'].apply(len)\ndf['label'] = df['generated'].apply(lambda x: 'Human' if x == 1 else 'AI')\ndf","metadata":{"execution":{"iopub.status.busy":"2024-03-16T06:20:12.229300Z","iopub.execute_input":"2024-03-16T06:20:12.229853Z","iopub.status.idle":"2024-03-16T06:20:12.611396Z","shell.execute_reply.started":"2024-03-16T06:20:12.229812Z","shell.execute_reply":"2024-03-16T06:20:12.610459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test_df = df[:1000]\n#test_df = df.sample(25, random_state = 28)\ntest_df = df.sample(10000, random_state = 28)\n\nprint(test_df)\nall_words = [word.lower() for word in test_df[\"text\"]]","metadata":{"execution":{"iopub.status.busy":"2024-03-16T06:21:37.151687Z","iopub.execute_input":"2024-03-16T06:21:37.152097Z","iopub.status.idle":"2024-03-16T06:21:37.182319Z","shell.execute_reply.started":"2024-03-16T06:21:37.152064Z","shell.execute_reply":"2024-03-16T06:21:37.181171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Exploration**","metadata":{}},{"cell_type":"code","source":"df.info()\ndf.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:48:40.881775Z","iopub.execute_input":"2024-03-16T05:48:40.882675Z","iopub.status.idle":"2024-03-16T05:48:41.478888Z","shell.execute_reply.started":"2024-03-16T05:48:40.882628Z","shell.execute_reply":"2024-03-16T05:48:41.477587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Total no. of rows: \")\nprint(df.shape[0])","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:48:43.585497Z","iopub.execute_input":"2024-03-16T05:48:43.586656Z","iopub.status.idle":"2024-03-16T05:48:43.594041Z","shell.execute_reply.started":"2024-03-16T05:48:43.586608Z","shell.execute_reply":"2024-03-16T05:48:43.593123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nax = df['label'].value_counts().plot(kind='bar', color='green')\nfor i, val in enumerate(df['generated'].value_counts().sort_index()):\n    ax.text(i, val, str(val), ha='center', va='bottom')\n\n# Adding title and labels\nplt.title('AI vs Human Text Data')\nplt.xlabel('Labels')\nplt.ylabel('Text Count')\n\n# Showing the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:41:40.298291Z","iopub.execute_input":"2024-03-16T05:41:40.298634Z","iopub.status.idle":"2024-03-16T05:41:40.534113Z","shell.execute_reply.started":"2024-03-16T05:41:40.298607Z","shell.execute_reply":"2024-03-16T05:41:40.532630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:48:47.113644Z","iopub.execute_input":"2024-03-16T05:48:47.114602Z","iopub.status.idle":"2024-03-16T05:48:47.123932Z","shell.execute_reply.started":"2024-03-16T05:48:47.114536Z","shell.execute_reply":"2024-03-16T05:48:47.122668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#DOES NOT WORK FOR SAMPLING\n\n'''nltk.download('punkt')\ntokenized_reviews = []\nfor i in range(len(test_df['text'])):\n\n    if type(test_df['text'][i])==str:\n        tokenized_reviews += [nltk.word_tokenize(test_df['text'][i])]\nprint(tokenized_reviews[0][:20])'''","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:41:40.551406Z","iopub.execute_input":"2024-03-16T05:41:40.551803Z","iopub.status.idle":"2024-03-16T05:41:40.568946Z","shell.execute_reply.started":"2024-03-16T05:41:40.551772Z","shell.execute_reply":"2024-03-16T05:41:40.567553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Works for sampling\nnltk.download('punkt')\n\ntokenized_reviews = []\n\nfor index, row in test_df.iterrows():\n    if type(row['text']) == str:\n        tokenized_reviews.append(nltk.word_tokenize(row['text']))\n\nprint(tokenized_reviews[0][:20])\n","metadata":{"execution":{"iopub.status.busy":"2024-03-16T06:21:41.141229Z","iopub.execute_input":"2024-03-16T06:21:41.141675Z","iopub.status.idle":"2024-03-16T06:21:41.243127Z","shell.execute_reply.started":"2024-03-16T06:21:41.141644Z","shell.execute_reply":"2024-03-16T06:21:41.240724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"docs_lower = [[w.lower() for w in doc] for doc in tokenized_reviews]\nprint(docs_lower[0][0:20])","metadata":{"execution":{"iopub.status.busy":"2024-03-16T06:21:43.556573Z","iopub.execute_input":"2024-03-16T06:21:43.556995Z","iopub.status.idle":"2024-03-16T06:21:43.565563Z","shell.execute_reply.started":"2024-03-16T06:21:43.556964Z","shell.execute_reply":"2024-03-16T06:21:43.564329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\ndocs_alpha = [[w for w in doc if re.search('^[a-z]+$', w)] for doc in docs_lower]\nprint(docs_alpha[0][0:20])","metadata":{"execution":{"iopub.status.busy":"2024-03-16T06:21:44.828243Z","iopub.execute_input":"2024-03-16T06:21:44.828672Z","iopub.status.idle":"2024-03-16T06:21:44.847497Z","shell.execute_reply.started":"2024-03-16T06:21:44.828641Z","shell.execute_reply":"2024-03-16T06:21:44.846122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_words = 0\nfor i in docs_alpha:\n    total_words += len(i)\nprint(total_words)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T06:21:46.195455Z","iopub.execute_input":"2024-03-16T06:21:46.195860Z","iopub.status.idle":"2024-03-16T06:21:46.201276Z","shell.execute_reply.started":"2024-03-16T06:21:46.195829Z","shell.execute_reply":"2024-03-16T06:21:46.200305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.corpus import stopwords\nnltk.download('stopwords')\nstop_list = stopwords.words('english')\nprint(stop_list)\ndocs_stop=[[w for w in doc if w not in stop_list] for doc in docs_alpha]\nprint(docs_stop[0][0:20])","metadata":{"execution":{"iopub.status.busy":"2024-03-16T06:21:47.412812Z","iopub.execute_input":"2024-03-16T06:21:47.413303Z","iopub.status.idle":"2024-03-16T06:21:47.456184Z","shell.execute_reply.started":"2024-03-16T06:21:47.413264Z","shell.execute_reply":"2024-03-16T06:21:47.455039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words_left= 0\nfor i in docs_stop:\n    words_left += len(i)\nprint(words_left)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T06:21:49.947134Z","iopub.execute_input":"2024-03-16T06:21:49.947533Z","iopub.status.idle":"2024-03-16T06:21:49.954684Z","shell.execute_reply.started":"2024-03-16T06:21:49.947504Z","shell.execute_reply":"2024-03-16T06:21:49.953181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"percent_stop = (total_words-words_left)/total_words*100\nprint('Percentage of stop words: {} %'.format(percent_stop))","metadata":{"execution":{"iopub.status.busy":"2024-03-16T06:21:51.969208Z","iopub.execute_input":"2024-03-16T06:21:51.969640Z","iopub.status.idle":"2024-03-16T06:21:51.975972Z","shell.execute_reply.started":"2024-03-16T06:21:51.969606Z","shell.execute_reply":"2024-03-16T06:21:51.974853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.stem.porter import *\ndocs_stem=[]\nscount= 0\nstemmer = PorterStemmer()\nfor i in docs_stop:\n    temp_list=[]\n    for w in i:\n        temp_list.append(stemmer.stem(w))\n        scount+= 1\n    docs_stem.append(temp_list)\nprint(docs_stem[0][0:20])\nprint(scount)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T06:21:53.803728Z","iopub.execute_input":"2024-03-16T06:21:53.804110Z","iopub.status.idle":"2024-03-16T06:21:53.940565Z","shell.execute_reply.started":"2024-03-16T06:21:53.804082Z","shell.execute_reply":"2024-03-16T06:21:53.939399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0,len(docs_stem)):\n    fdist = nltk.FreqDist(docs_stem[i])\nprint(fdist.most_common(10))","metadata":{"execution":{"iopub.status.busy":"2024-03-16T06:21:55.542568Z","iopub.execute_input":"2024-03-16T06:21:55.543139Z","iopub.status.idle":"2024-03-16T06:21:55.558606Z","shell.execute_reply.started":"2024-03-16T06:21:55.543094Z","shell.execute_reply":"2024-03-16T06:21:55.557200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Polarity Scores**","metadata":{}},{"cell_type":"markdown","source":"**Adding polarity & subjectivity scores for each line of text. Also added sentiment scores, which quantifies the emotion of each line of text, in terms of positivity, negativity, and neutrality.**","metadata":{}},{"cell_type":"code","source":"!pip install textblob","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:41:40.964235Z","iopub.execute_input":"2024-03-16T05:41:40.965133Z","iopub.status.idle":"2024-03-16T05:41:53.356674Z","shell.execute_reply.started":"2024-03-16T05:41:40.965088Z","shell.execute_reply":"2024-03-16T05:41:53.355220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from textblob import TextBlob\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nanalyzer = SentimentIntensityAnalyzer()\nprint(analyzer)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:41:53.361674Z","iopub.execute_input":"2024-03-16T05:41:53.362098Z","iopub.status.idle":"2024-03-16T05:41:53.378493Z","shell.execute_reply.started":"2024-03-16T05:41:53.362062Z","shell.execute_reply":"2024-03-16T05:41:53.377001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentences = test_df[\"text\"]\n\ntest_df['polarity_scores'] = {}\ntest_df","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:41:53.380151Z","iopub.execute_input":"2024-03-16T05:41:53.380637Z","iopub.status.idle":"2024-03-16T05:41:53.406703Z","shell.execute_reply.started":"2024-03-16T05:41:53.380597Z","shell.execute_reply":"2024-03-16T05:41:53.405300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"polarity_scores = []\nfor i in range(len(sentences)):\n    my_analyzer = analyzer.polarity_scores(sentences.iloc[i])\n    polarity_scores.append(my_analyzer)\ntest_df['polarity_scores'] = polarity_scores\ntest_df","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:41:53.408434Z","iopub.execute_input":"2024-03-16T05:41:53.408808Z","iopub.status.idle":"2024-03-16T05:41:53.560510Z","shell.execute_reply.started":"2024-03-16T05:41:53.408770Z","shell.execute_reply":"2024-03-16T05:41:53.559117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def unpack_dictionary(test_df):\n    return pd.Series(test_df['polarity_scores'])\n\nnew_columns = test_df.apply(unpack_dictionary, axis=1)\ntest_df = pd.concat([test_df, new_columns], axis=1)\ntest_df.drop(['polarity_scores'], axis=1, inplace=True)\ntest_df","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:41:53.562149Z","iopub.execute_input":"2024-03-16T05:41:53.562561Z","iopub.status.idle":"2024-03-16T05:41:53.597437Z","shell.execute_reply.started":"2024-03-16T05:41:53.562530Z","shell.execute_reply":"2024-03-16T05:41:53.596340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generating subjectivity scores\nsubjectivity_scores = []\nfor i in range(len(sentences)):\n    sub_score = TextBlob(sentences.iloc[i]).subjectivity\n    subjectivity_scores.append(sub_score)\ntest_df['subjectivity_score'] = subjectivity_scores\ntest_df","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:41:53.598988Z","iopub.execute_input":"2024-03-16T05:41:53.599365Z","iopub.status.idle":"2024-03-16T05:41:53.701433Z","shell.execute_reply.started":"2024-03-16T05:41:53.599335Z","shell.execute_reply":"2024-03-16T05:41:53.699833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ****Added document statistics****","metadata":{}},{"cell_type":"markdown","source":"Mean of words per text","metadata":{}},{"cell_type":"code","source":"total=0\nfor i in docs_alpha:\n    total += len(i)\nprint(total/len(docs_alpha))","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:41:53.703188Z","iopub.execute_input":"2024-03-16T05:41:53.703783Z","iopub.status.idle":"2024-03-16T05:41:53.711108Z","shell.execute_reply.started":"2024-03-16T05:41:53.703598Z","shell.execute_reply":"2024-03-16T05:41:53.709656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"unique word count","metadata":{}},{"cell_type":"code","source":"words = []\ncount = 0\nfor i in docs_stem:\n    for j in i:\n        if j not in words:\n            words.append(j)\n            count += 1\nprint(count)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:41:53.712978Z","iopub.execute_input":"2024-03-16T05:41:53.713789Z","iopub.status.idle":"2024-03-16T05:41:53.766191Z","shell.execute_reply.started":"2024-03-16T05:41:53.713723Z","shell.execute_reply":"2024-03-16T05:41:53.765287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Cosine Similarity**","metadata":{}},{"cell_type":"code","source":"!python --version","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:41:53.767452Z","iopub.execute_input":"2024-03-16T05:41:53.767936Z","iopub.status.idle":"2024-03-16T05:41:54.937194Z","shell.execute_reply.started":"2024-03-16T05:41:53.767907Z","shell.execute_reply":"2024-03-16T05:41:54.935497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nTransformer libraries useful to using the pretrained model and data preprocessing\n\"\"\"\n\"\"\"import torch\nfrom keras.preprocessing.sequence import pad_sequences\nfrom transformers import BertTokenizer, AutoModelForSequenceClassification\n\n\"\"\"\n#Similarity search section: cosine similarity search and facebook AI research library\n\"\"\"\nfrom sklearn.metrics.pairwise import cosine_similarity\n!pip install faiss-gpu # please uncomment this line when you're running the notebook for the first time\nimport faiss\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:41:54.940043Z","iopub.execute_input":"2024-03-16T05:41:54.940630Z","iopub.status.idle":"2024-03-16T05:41:54.950993Z","shell.execute_reply.started":"2024-03-16T05:41:54.940551Z","shell.execute_reply":"2024-03-16T05:41:54.949386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"# Get the SciBERT pretrained model path from Allen AI repo\npretrained_model = 'allenai/scibert_scivocab_uncased'\n\n# Get the tokenizer from the previous path\nsciBERT_tokenizer = BertTokenizer.from_pretrained(pretrained_model, \n                                          do_lower_case=True)\n\n# Get the model\nmodel = AutoModelForSequenceClassification.from_pretrained(pretrained_model,\n                                                          output_attentions=False,\n                                                          output_hidden_states=True)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:41:54.959868Z","iopub.execute_input":"2024-03-16T05:41:54.960235Z","iopub.status.idle":"2024-03-16T05:41:54.968467Z","shell.execute_reply.started":"2024-03-16T05:41:54.960207Z","shell.execute_reply":"2024-03-16T05:41:54.967287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"from sklearn.metrics.pairwise import cosine_similarity\ncosine_similarity(docs_stem)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:41:54.971347Z","iopub.execute_input":"2024-03-16T05:41:54.971733Z","iopub.status.idle":"2024-03-16T05:41:54.980409Z","shell.execute_reply.started":"2024-03-16T05:41:54.971703Z","shell.execute_reply":"2024-03-16T05:41:54.979022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Readability Scores**","metadata":{}},{"cell_type":"code","source":"!pip install textstat\n!pip install py-readability-metrics\n!pip install readability-lxml","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:41:54.983423Z","iopub.execute_input":"2024-03-16T05:41:54.983960Z","iopub.status.idle":"2024-03-16T05:42:32.275911Z","shell.execute_reply.started":"2024-03-16T05:41:54.983928Z","shell.execute_reply":"2024-03-16T05:42:32.274625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import textstat\n\n# Function to calculate Flesch Reading Ease score\ndef calculate_flesch_reading_ease(text):\n    return textstat.flesch_reading_ease(text)\n\n# Apply the function to the 'text' column\ntest_df['flesch_reading_ease_score'] = test_df['text'].apply(calculate_flesch_reading_ease)\n\ndef calculate_flesch_kincaid(text):\n#     return Readability(text).flesch_kincaid()\n    return textstat.flesch_kincaid_grade(text)\n\ntest_df['flesch_kincaid_grade'] = test_df['text'].apply(calculate_flesch_kincaid)\n\nprint(test_df.head())","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:42:32.279153Z","iopub.execute_input":"2024-03-16T05:42:32.279557Z","iopub.status.idle":"2024-03-16T05:42:32.364208Z","shell.execute_reply.started":"2024-03-16T05:42:32.279522Z","shell.execute_reply":"2024-03-16T05:42:32.363071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Perplexity Scores**\n\n","metadata":{}},{"cell_type":"code","source":"from transformers import GPT2Tokenizer, GPT2LMHeadModel\nimport torch\n\n# Load pre-trained GPT-2 tokenizer\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n\n# Load pre-trained GPT-2 language model\nmodel = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n\n\ndef calculate_perplexity(text):\n    # Tokenizes the input text, but some are too long, thus truncation is activated\n    input_ids = tokenizer.encode(text, return_tensors=\"pt\", truncation = True)\n\n    # Forward pass through the language model\n    with torch.no_grad():\n        outputs = model(input_ids=input_ids, labels=input_ids)\n    \n    # Compute perplexity from the loss\n    loss = outputs.loss\n    perplexity = torch.exp(loss)\n    \n    return perplexity.item()\n\ntest_df['Perplexity Score'] = test_df['text'].apply(calculate_perplexity) \ntest_df","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:42:32.365760Z","iopub.execute_input":"2024-03-16T05:42:32.366104Z","iopub.status.idle":"2024-03-16T05:43:09.727912Z","shell.execute_reply.started":"2024-03-16T05:42:32.366077Z","shell.execute_reply":"2024-03-16T05:43:09.726744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Discourse markers**\nDiscourse markers: words/phrases used to connect, manage, and organize ideas without changing their original meaning (e.g. however, therefore, anyway, secondly, etc) \\\nSource: https://www.eapfoundation.com/vocab/academic/other/dcl/ (list of 632 discourse connectors)","metadata":{}},{"cell_type":"code","source":"dcl_list = ['and','or','also','much', 'then','again', 'too', 'increasingly', 'similarly', 'further', 'namely', 'thus', 'indeed',\n 'e.g.', 'specifically', 'i.e.', 'especially', 'usually', 'certainly', 'generally', 'extremely', 'mostly', 'actually', 'basically',\n 'surely', 'inevitably', 'clearly', 'approximately', 'resembling', 'exactly', 'unlike', 'because', 'therefore', 'if', 'somehow',\n 'hence', 'consequently', 'thereby', 'otherwise', 'since', 'however', 'while', 'althoughthough', 'instead', 'yet', 'worse',\n 'except', 'whereas', 'albeit', 'admittedly', 'sometimes', 'until', 'eventually', 'constantly', 'meanwhile', 'beforehand',\n 'meantime', 'overall', 'finally', 'firstly', 'secondly', 'lastly', 'conclude', 'summarize', 'altogether', 'briefly']\n\ndcl_count_list = []\ntest_df['split_text'] = test_df['text'].str.split(' ')\n\n# Iterate through each word in the DataFrame\nfor text_list in test_df['split_text']:\n    dcl_count = 0\n    # Check if the word is in the word list\n    for word in text_list:\n        if word in dcl_list:\n        # Increment counter if the word is found\n            dcl_count += 1\n    dcl_count_list.append(dcl_count)\n    \ntest_df['no_discourse_markers'] = dcl_count_list\ntest_df","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:43:09.729374Z","iopub.execute_input":"2024-03-16T05:43:09.729749Z","iopub.status.idle":"2024-03-16T05:43:09.801704Z","shell.execute_reply.started":"2024-03-16T05:43:09.729721Z","shell.execute_reply":"2024-03-16T05:43:09.800501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Absolute number of personal pronouns**","metadata":{}},{"cell_type":"code","source":"pronouns_list = ['i','you','he','him','her','she','they','them','it','we','me','us']\n\npronouns_count_list = []\ntest_df['split_text'] = test_df['text'].str.split(' ')\n\n# Iterate through each word in the DataFrame\nfor text_list in test_df['split_text']:\n    pronouns_count = 0\n    # Check if the word is in the word list\n    for word in text_list:\n        if word in pronouns_list:\n        # Increment counter if the word is found\n            pronouns_count += 1\n    pronouns_count_list.append(pronouns_count)\n    \n# Display the count\ntest_df['no_pronouns'] = pronouns_count_list\ntest_df\n#test_df.drop(['B', 'C'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:43:09.803365Z","iopub.execute_input":"2024-03-16T05:43:09.803707Z","iopub.status.idle":"2024-03-16T05:43:09.863730Z","shell.execute_reply.started":"2024-03-16T05:43:09.803680Z","shell.execute_reply":"2024-03-16T05:43:09.862607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Mean/stdev of words/unique words per sentence & absolute number of personal pronouns**","metadata":{}},{"cell_type":"code","source":"test_df['mean_words_per_sentence'] = test_df['text'].str.split(' ').str.len()/test_df['text'].str.split('.').str.len()\ntest_df","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:43:09.866347Z","iopub.execute_input":"2024-03-16T05:43:09.866705Z","iopub.status.idle":"2024-03-16T05:43:09.928730Z","shell.execute_reply.started":"2024-03-16T05:43:09.866676Z","shell.execute_reply":"2024-03-16T05:43:09.927415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Extract grammatical errors**","metadata":{}},{"cell_type":"code","source":"import re\n\n# Define regular expressions for common grammatical errors\nerror_patterns = [\n    (r'\\b\\w+(?:\\'[st])\\b', \"Use 's or 'd instead of '\"),\n    (r'\\bis\\s+(?:\\w+ing\\b|\\w+\\s)', \"Use the correct form of the verb after 'is'\"),\n    (r'\\b(?:\\w+ed|\\w+en)\\s+\\w+', \"Check for correct verb forms (past participles)\"),\n    (r'\\b(?:a|an)\\s+[aeiou]', \"Use 'a' or 'an' correctly before a word\"),\n    (r'\\b(?:too|to|two)\\b', \"Use the correct form of 'to'\"),\n    (r'\\b(?:their|there|they\\'re)\\b', \"Use the correct form of 'their', 'there', or 'they're'\"),\n    (r'\\b(?:your|you\\'re)\\b', \"Use the correct form of 'your' or 'you're'\"),\n    (r'\\b(?:its|it\\'s)\\b', \"Use the correct form of 'its' or 'it's'\")\n]\n\n# Function to detect grammatical errors using regular expressions\ndef detect_grammatical_errors(text):\n    errors = []\n    for pattern, description in error_patterns:\n        matches = re.findall(pattern, text)\n        if matches:\n            errors.extend([(match, description) for match in matches])\n    return len(errors)\n\n# Apply function to DataFrame\ntest_df['grammatical_errors'] = test_df['text'].apply(detect_grammatical_errors)\n\nprint(test_df.head())","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:43:09.930792Z","iopub.execute_input":"2024-03-16T05:43:09.931192Z","iopub.status.idle":"2024-03-16T05:43:09.967521Z","shell.execute_reply.started":"2024-03-16T05:43:09.931161Z","shell.execute_reply":"2024-03-16T05:43:09.966253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Named Entity Recognition Count**","metadata":{}},{"cell_type":"code","source":"!pip install spacy\nimport spacy\n# python -m spacy download en_core_web_sm","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:43:09.969253Z","iopub.execute_input":"2024-03-16T05:43:09.969891Z","iopub.status.idle":"2024-03-16T05:43:22.460585Z","shell.execute_reply.started":"2024-03-16T05:43:09.969846Z","shell.execute_reply":"2024-03-16T05:43:22.459332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load SpaCy model\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Function to perform named entity recognition and count named entities\ndef count_named_entities(text):\n    doc = nlp(text)\n    named_entity_counts = {}\n    for ent in doc.ents:\n        entity_type = ent.label_\n        if entity_type in named_entity_counts:\n            named_entity_counts[entity_type] += 1\n        else:\n            named_entity_counts[entity_type] = 1\n    return len(named_entity_counts)\n\n# Apply function to DataFrame\ntest_df['named_entity_counts'] = test_df['text'].apply(count_named_entities)\n\nprint(test_df.head())","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:43:22.462793Z","iopub.execute_input":"2024-03-16T05:43:22.463949Z","iopub.status.idle":"2024-03-16T05:43:25.467608Z","shell.execute_reply.started":"2024-03-16T05:43:22.463907Z","shell.execute_reply":"2024-03-16T05:43:25.466496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.to_csv(\"feature_output_10k.csv\")\nprint('Y')","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:43:25.469018Z","iopub.execute_input":"2024-03-16T05:43:25.469479Z","iopub.status.idle":"2024-03-16T05:43:25.486225Z","shell.execute_reply.started":"2024-03-16T05:43:25.469447Z","shell.execute_reply":"2024-03-16T05:43:25.484974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}